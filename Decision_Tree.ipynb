{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae30c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0edcb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [ 'Class Name','Left weight','Left distance','Right weight','Right distance']\n",
    "df = pd.read_csv('balance-scale.data',names=col,sep=',')\n",
    "X = df.to_numpy()\n",
    "X = np.delete(X, 0, 1)\n",
    "y = df['Class Name'].to_numpy()\n",
    "#print(X.shape)\n",
    "#print(y.shape)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e8b961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 4 1 5]\n",
      " [1 4 3 4]\n",
      " [5 1 5 3]\n",
      " ...\n",
      " [3 1 5 1]\n",
      " [4 3 3 1]\n",
      " [1 5 1 3]]\n",
      "['L' 'R' 'R' 'R' 'B' 'L' 'R' 'B' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'R'\n",
      " 'B' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'R' 'R'\n",
      " 'R' 'R' 'R' 'L' 'R' 'R' 'L' 'B' 'R' 'L' 'B' 'R' 'R' 'R' 'L' 'L' 'B' 'L'\n",
      " 'R' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'L' 'L' 'L' 'L' 'R' 'L'\n",
      " 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'B' 'L' 'R' 'R' 'R'\n",
      " 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'B'\n",
      " 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'B'\n",
      " 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'B' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'L'\n",
      " 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'R'\n",
      " 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'R'\n",
      " 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'B' 'L' 'R' 'L' 'L' 'R' 'L' 'L'\n",
      " 'R' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R'\n",
      " 'L' 'R' 'R' 'L' 'R' 'B' 'B' 'B' 'R' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'B'\n",
      " 'R' 'R' 'R' 'L' 'L' 'L' 'L' 'L' 'L' 'B' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L'\n",
      " 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'R' 'L'\n",
      " 'L' 'B' 'L' 'B' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L'\n",
      " 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'B' 'L' 'R' 'R' 'R' 'R' 'R' 'R'\n",
      " 'L' 'L' 'L' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'B' 'R' 'L' 'R'\n",
      " 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L'\n",
      " 'B' 'R' 'R' 'R' 'B' 'R' 'R' 'L' 'R' 'L' 'B' 'R' 'R' 'B' 'R' 'L' 'R' 'R'\n",
      " 'B' 'B' 'L' 'L' 'L' 'L' 'L' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L'\n",
      " 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'B' 'L' 'L' 'R' 'L' 'R' 'R' 'R'\n",
      " 'L' 'L' 'L' 'B' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'R' 'L' 'B' 'R' 'R' 'L' 'L'\n",
      " 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'B' 'R' 'B' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R'\n",
      " 'R' 'L' 'R' 'L' 'L']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state=42)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "#print(np.unique(X_train[col[1]]))\n",
    "#print(X_train['Left weight'])\n",
    "#asd = [x for x in X_train['Left weight'] if x > 2]\n",
    "#print(y_train['Class Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac6a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "from numpy import inf\n",
    "\n",
    "class Node:#\n",
    "    def __init__(self, feature=None, condition=None, left=None, right=None, value=None):#\n",
    "        self.feature = feature\n",
    "        self.condition = condition\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "class DecisionTreeClassifier:#\n",
    "    def __init__(self, min_samples_split=1, max_depth=5, number_of_features=None):#\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.number_of_features = number_of_features\n",
    "\n",
    "    def fit(self, X_train, y_train):#\n",
    "        self.number_of_features = X_train.shape[1]\n",
    "        self.root = self.build_tree(X_train, y_train)\n",
    "\n",
    "    def predict(self, X):#\n",
    "        # data reshapping\n",
    "        y_predict = np.array([self.traversal(x, self.root) for x in X])\n",
    "        y_predict_arr = []\n",
    "        for x in y_predict:\n",
    "            if (x == 0.4759725400457666):\n",
    "                y_predict_arr.append('L')\n",
    "            elif (x == 0.45308924485125857):\n",
    "                y_predict_arr.append('R')\n",
    "            elif (x == 0.07093821510297482):\n",
    "                y_predict_arr.append('B')\n",
    "        return np.array(y_predict_arr)\n",
    "\n",
    "    def build_tree(self, X_train, y_train, current_depth=0):#\n",
    "        number_of_samples = X_train.shape[0]\n",
    "        number_of_features = X_train.shape[1]\n",
    "        \n",
    "        if (current_depth >= self.max_depth or self.min_samples_split > number_of_samples):\n",
    "            return Node(value=mode(y_train))\n",
    "        feature_split, condition_split = self.best_criteria(X_train, y_train, np.arange(0, number_of_features))\n",
    "        left_branch = np.argwhere(X_train[:, feature_split] <= condition_split).flatten()\n",
    "        right_branch = np.argwhere(X_train[:, feature_split] > condition_split).flatten()\n",
    "        left_node = self.build_tree(X_train[left_branch, :], y_train[left_branch], current_depth + 1)\n",
    "        right_node = self.build_tree(X_train[right_branch, :], y_train[right_branch], current_depth + 1)\n",
    "        return Node(feature_split, condition_split, left_node, right_node)\n",
    "\n",
    "    def best_criteria(self, X_train, y_train, features):#\n",
    "        max_ig, split, condition = -inf, -inf, -inf\n",
    "        for feat in features:\n",
    "            # array of each possible condition for this feature\n",
    "            conditions = np.unique(X_train[:, feat])\n",
    "            for cond in conditions:\n",
    "                gain = self.information_gain(X_train[:, feat], y_train, cond)\n",
    "                # best information gain\n",
    "                if gain > max_ig:\n",
    "                    # records feature and condition for best IG\n",
    "                    max_ig, split, condition = gain, feat, cond\n",
    "        return split, condition\n",
    "\n",
    "    def information_gain(self, X_train, y_train, cond):#\n",
    "        left_branch = np.argwhere(X_train <= cond).flatten()\n",
    "        right_branch = np.argwhere(X_train > cond).flatten()\n",
    "        if len(left_branch) == 0 or len(right_branch) == 0:\n",
    "            return 0\n",
    "        pXl = len(left_branch) / len(y_train) # p(X <=)\n",
    "        pXr = len(right_branch) / len(y_train) # p(X >)\n",
    "        HYXl = self.entropy(y_train[left_branch]) # H(Y|X <=)\n",
    "        HYXr = self.entropy(y_train[right_branch]) # H(Y|X >)\n",
    "        return self.entropy(y_train) - (pXl * HYXl + pXr * HYXr) #H(Y) - H(Y|X)\n",
    "\n",
    "    def traversal(self, root, node):#\n",
    "        if node.value != None:\n",
    "            return node.value\n",
    "        elif root[node.feature] <= node.condition:\n",
    "            return self.traversal(root, node.left)\n",
    "        else:\n",
    "            return self.traversal(root, node.right)\n",
    "    \n",
    "    def entropy(self, y):#\n",
    "        probability_of_y = y\n",
    "        nB, nR, nL = 0, 0, 0\n",
    "        probability_of_y[probability_of_y == 'B'] = 1\n",
    "        probability_of_y[probability_of_y == 'R'] = 2\n",
    "        probability_of_y[probability_of_y == 'L'] = 3\n",
    "        for x in probability_of_y:\n",
    "            if (x == 1):\n",
    "                nB += 1\n",
    "            elif (x == 2):\n",
    "                nR += 1\n",
    "            elif (x == 3):\n",
    "                nL += 1\n",
    "        # p(y)\n",
    "        probability_of_y[probability_of_y == 1] = nB/len(probability_of_y)\n",
    "        probability_of_y[probability_of_y == 2] = nR/len(probability_of_y)\n",
    "        probability_of_y[probability_of_y == 3] = nL/len(probability_of_y)\n",
    "        return -np.sum([p * np.log(p) for p in probability_of_y]) # H(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088f57e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6595744680851063"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model = DecisionTreeClassifier(min_samples_split=5, max_depth=3)\n",
    "clf_model.fit(X_train,y_train)\n",
    "y_predict = clf_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2689d51f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
